{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep Kit - Hello World (Pure Python)\n",
    "\n",
    "This notebook guides you through running your first data preparation transformation using the data-prep-kit. In this example, we will demonstrate a transformation that takes PDF files as input and extracts their content.\n",
    "\n",
    "This notebook is a pure python version, for ray version see this notebook: [Run_your_first_transform_ray.ipynb](Run_your_first_transform_ray.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Setting up Python Dev Environment\n",
    "\n",
    "Please follow instructions from [Getting started section](../../README.md#gettingstarted) to setup your python development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Get Data\n",
    "\n",
    "For this example, we will show PDF processing capabilities of DPK.  And we will download and use this PDF documents\n",
    "\n",
    "- [IBM Granite model](https://arxiv.org/abs/2405.04324)\n",
    "- [Attention is all you need](https://arxiv.org/pdf/1706.03762) - seminal paper on transformer/attention architecture\n",
    "\n",
    "The code below will download the PDF.  Feel free to try your own PDFs to test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'Input-Test-Data'\n",
    "OUTPUT_DIR = 'Output-Test-Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input-Test-Data/Granite_code_models.pdf (1.27 MB) downloaded successfully.\n",
      "\n",
      "Input-Test-Data/attention_is_all_you_need.pdf (2.22 MB) downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "## This cell will download the input files\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "from humanfriendly import format_size\n",
    "\n",
    "def download_file(url, local_file, chunk_size=1024*1024):\n",
    "    # Check if the local file already exists\n",
    "    if os.path.exists(local_file):\n",
    "        file_size = format_size(os.path.getsize(local_file))\n",
    "        print(f\"Local file '{local_file}' ({file_size}) already exists. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "\n",
    "    # Stream the file download\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "        print()\n",
    "        file_size = format_size(os.path.getsize(local_file))\n",
    "        print(f\"{local_file} ({file_size}) downloaded successfully.\")\n",
    "## --- end: download_file ------\n",
    "\n",
    "## setup input/output directories\n",
    "shutil.os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "shutil.os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "## Download PDF files\n",
    "download_file (url = 'https://arxiv.org/pdf/2405.04324', local_file = os.path.join(INPUT_DIR, 'Granite_code_models.pdf' ))\n",
    "download_file (url = 'https://arxiv.org/pdf/1706.03762', local_file = os.path.join(INPUT_DIR, 'attention_is_all_you_need.pdf' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Extract Text from PDF \n",
    "\n",
    "This code is designed to set up a data transformation process that extracts text from PDF.  We will save the output as parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ast\n",
    "\n",
    "# Utilities from the data-prep-kit's data-processing-lib library provide functions and classes for parameter management, \n",
    "from pdf2parquet_transform import (pdf2parquet_contents_type_cli_param, pdf2parquet_contents_types,)\n",
    "from data_processing.utils import GB, ParamsUtils\n",
    "\n",
    "\n",
    "ingest_config = {\n",
    "    pdf2parquet_contents_type_cli_param: pdf2parquet_contents_types.JSON,\n",
    "}\n",
    "\n",
    "#local_conf: A dictionary specifying the local input and output folders where the PDF files will be read from and the transformed data will be saved.\n",
    "local_conf = {\n",
    "    \"input_folder\": INPUT_DIR,\n",
    "    \"output_folder\": OUTPUT_DIR,\n",
    "}\n",
    "\n",
    "#params: A dictionary containing various runtime parameters for the transformation.\n",
    "#data_local_config: Configuration for local data access, such as input and output folders, converted into a format compatible with the transformation using ParamsUtils.convert_to_ast.\n",
    "#data_files_to_use: Specifies that only PDF files (['.pdf']) will be used as input data.\n",
    "\n",
    "params = {\n",
    "    \"data_local_config\": ParamsUtils.convert_to_ast(local_conf),\n",
    "    \"data_files_to_use\": ast.literal_eval(\"['.pdf']\"),\n",
    "}\n",
    "sys.argv = ParamsUtils.dict_to_req(d=(params | ingest_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to run the transformation.\n",
    "\n",
    "You will notice, that the code will download models to execute the transformation.  These models will be used to process PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:36 INFO - pdf2parquet parameters are : {'artifacts_path': None, 'contents_type': <pdf2parquet_contents_types.JSON: 'application/json'>, 'do_table_structure': True, 'do_ocr': False}\n",
      "00:21:36 INFO - pipeline id pipeline_id\n",
      "00:21:36 INFO - job details {'job category': 'preprocessing', 'job name': 'pdf2parquet', 'job type': 'pure python', 'job id': 'job_id'}\n",
      "00:21:36 INFO - code location None\n",
      "00:21:36 INFO - data factory data_ is using local data access: input_folder - Input-Test-Data output_folder - Output-Test-Data\n",
      "00:21:36 INFO - data factory data_ max_files -1, n_sample -1\n",
      "00:21:36 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.pdf'], files to checkpoint ['.parquet']\n",
      "00:21:36 INFO - orchestrator pdf2parquet started at 2024-09-04 00:21:36\n",
      "00:21:36 INFO - Number of files is 2, source profile {'max_file_size': 2.112621307373047, 'min_file_size': 1.2146415710449219, 'total_file_size': 3.3272628784179688}\n",
      "00:21:36 INFO - Initializing models\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81aa36c6436e4331bc67bd80c5d72945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/apps/anaconda3/envs/data-prep-kit-3-py311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "00:22:11 INFO - Completed 1 files (50.0%) in 0.4056213855743408 min\n",
      "00:22:21 INFO - Completed 2 files (100.0%) in 0.5788233876228333 min\n",
      "00:22:21 INFO - done flushing in 5.9604644775390625e-06 sec\n",
      "00:22:22 INFO - Completed execution in 0.7664824485778808 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tranformation run completed successfully\n",
      "CPU times: user 1min 56s, sys: 1.1 s, total: 1min 57s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from data_processing.runtime.pure_python import PythonTransformLauncher\n",
    "from pdf2parquet_transform_python import Pdf2ParquetPythonTransformConfiguration\n",
    "\n",
    "\n",
    "launcher = PythonTransformLauncher(Pdf2ParquetPythonTransformConfiguration())\n",
    "return_code = launcher.launch()\n",
    "\n",
    "if return_code == 0:\n",
    "    print (f\"✅ Tranformation run completed successfully\")\n",
    "else:\n",
    "    raise Exception (\"❌ Transformation run failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Inspect the generated output\n",
    "\n",
    "We will use pandas to read parquet files and display.\n",
    "\n",
    "You should see one-entry per PDF input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "## Reads parquet files in a folder into a pandas dataframe \n",
    "def read_parquet_files_as_df (parquet_dir):\n",
    "    parquet_files = glob.glob(f'{parquet_dir}/*.parquet')\n",
    "\n",
    "    # read each parquet file into a DataFrame and store in a list\n",
    "    dfs = [pd.read_parquet (f) for f in parquet_files]\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    data_df = pd.concat(dfs, ignore_index=True)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention_is_all_you_need.pdf</td>\n",
       "      <td>{\"_name\":\"\",\"type\":\"pdf-document\",\"description...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "      <td>1a75f9df-e478-43b6-bab6-075e6e4cc52c</td>\n",
       "      <td>pdf</td>\n",
       "      <td>e8417f232bdadc1760dd998dd64ee650f6140493f1685e...</td>\n",
       "      <td>131173</td>\n",
       "      <td>2024-09-04T00:22:21.740447</td>\n",
       "      <td>10.386293</td>\n",
       "      <td>attention_is_all_you_need.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Granite_code_models.pdf</td>\n",
       "      <td>{\"_name\":\"\",\"type\":\"pdf-document\",\"description...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>320</td>\n",
       "      <td>aaf7c1f6-592b-4b5e-94d3-d79d887e6be2</td>\n",
       "      <td>pdf</td>\n",
       "      <td>153d0ed14d3c71894252d0e8584479ec71d793a8d9d7ea...</td>\n",
       "      <td>584826</td>\n",
       "      <td>2024-09-04T00:22:11.343103</td>\n",
       "      <td>24.315634</td>\n",
       "      <td>Granite_code_models.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  \\\n",
       "0  attention_is_all_you_need.pdf   \n",
       "1        Granite_code_models.pdf   \n",
       "\n",
       "                                            contents  num_pages  num_tables  \\\n",
       "0  {\"_name\":\"\",\"type\":\"pdf-document\",\"description...         15           4   \n",
       "1  {\"_name\":\"\",\"type\":\"pdf-document\",\"description...         28          17   \n",
       "\n",
       "   num_doc_elements                           document_id  ext  \\\n",
       "0               193  1a75f9df-e478-43b6-bab6-075e6e4cc52c  pdf   \n",
       "1               320  aaf7c1f6-592b-4b5e-94d3-d79d887e6be2  pdf   \n",
       "\n",
       "                                                hash    size  \\\n",
       "0  e8417f232bdadc1760dd998dd64ee650f6140493f1685e...  131173   \n",
       "1  153d0ed14d3c71894252d0e8584479ec71d793a8d9d7ea...  584826   \n",
       "\n",
       "                date_acquired  pdf_convert_time                source_filename  \n",
       "0  2024-09-04T00:22:21.740447         10.386293  attention_is_all_you_need.pdf  \n",
       "1  2024-09-04T00:22:11.343103         24.315634        Granite_code_models.pdf  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = read_parquet_files_as_df(OUTPUT_DIR)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[\\n'\n",
      " '    '\n",
      " '\"{\\\\\"_name\\\\\":\\\\\"\\\\\",\\\\\"type\\\\\":\\\\\"pdf-document\\\\\",\\\\\"description\\\\\":{\\\\\"logs\\\\\":[]},\\\\\"file-info\\\\\":{\\\\\"filename\\\\\":\\\\\"attention_is_all_you_need.pdf\\\\\",\\\\\"document-hash\\\\\":\\\\\"bdfaa68d8984f0dc02beaca527b76f207d99b666d31d1da728ee0728182df697\\\\\",\\\\\"#-pages\\\\\":15,\\\\\"page-hashes\\\\\":[{\\\\\"hash\\\\\":\\\\\"8834a09ad99e9297886c9f8ad786c2784b7dc66dc6e6adfeff6bf2c1f07926d6\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":1},{\\\\\"hash\\\\\":\\\\\"72ded7022ad3cbfa9b5c4377a9c9b44511251f9489973956c23d2f3321e6307e\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":2},{\\\\\"hash\\\\\":\\\\\"38733274891513257d051950018621d95f73d05d5c70bfd7331def2f1194973d\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":3},{\\\\\"hash\\\\\":\\\\\"699ed16bf81021d0f86374d05c7b4b2b1049e63a28d2951ec1fb930747d755b9\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":4},{\\\\\"hash\\\\\":\\\\\"a17e6b313bdd51eff07a824253eff394d78ae1d6ebc985de3580bdfece38d2e1\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":5},{\\\\\"hash\\\\\":\\\\\"b3e9b63f2e8728fa83a5b7d911df2827585cf6040d2a4734cb3b44be264da6b6\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":6},{\\\\\"hash\\\\\":\\\\\"7b23bd1c80383b757a39456a4fd95ed2e9aaefd6a04512f181279c27a66c54a4\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":7},{\\\\\"hash\\\\\":\\\\\"c1dbbbf5b2ad441bf20149c26fc440a95f714987edf1f39690d703e67699dbc4\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":8},{\\\\\"hash\\\\\":\\\\\"ae2f68db548ba7a95d11ba1a1f0e36ca46c7d71d40a27c73dc56cf32932a9638\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":9},{\\\\\"hash\\\\\":\\\\\"58c67da2ef05339a90ab5c62b29eece0f60a7d8bb2f9eb390ba45a6d49e042f5\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":10},{\\\\\"hash\\\\\":\\\\\"b39d3fefe795d9d05aad7432498b5baeee7b255ed2da5bc88f60c051b8fae865\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":11},{\\\\\"hash\\\\\":\\\\\"1e5bf23dc7cd6799ee19684b7152560e0bda459b639ac3ea3f6f3fabf96362a4\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":12},{\\\\\"hash\\\\\":\\\\\"0ea258bf68e3835a534da65a943f679a19d02a19ae9b8afe9cd34af2cd29e9c4\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":13},{\\\\\"hash\\\\\":\\\\\"34c515052914fa661b7cedf6a25d7d4bd22a4d329971f74b9d1e75b3f6f02d16\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":14},{\\\\\"hash\\\\\":\\\\\"6ab332fddb6e68c5979d7481a53c9b75d91ac31564cad8972e3fa12cd7362769\\\\\",\\\\\"model\\\\\":\\\\\"default\\\\\",\\\\\"page\\\\\":15}]},\\\\\"main-text\\\\\":[{\\\\\"text\\\\\":\\\\\"arXiv:1706')\n"
     ]
    }
   ],
   "source": [
    "# Inspect contents\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "column_list = output_df['contents'].tolist()\n",
    "column_json = json.dumps(column_list, indent=4)\n",
    "pprint.pprint(column_json[:2000]) # display first few lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-prep-kit-3-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
